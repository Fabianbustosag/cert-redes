{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIwyL33xXxN5"
      },
      "source": [
        "# Regresión utilizando redes neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Bp0tdq2Sb7"
      },
      "source": [
        "\n",
        "Importar librerías necesarias:\n",
        "+ torch\n",
        "+ scikit-learn\n",
        "+ matplotlib\n",
        "+ seaborn\n",
        "+ pandas\n",
        "+ numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ywMrF4oKDzj"
      },
      "outputs": [],
      "source": [
        "import "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyegUTg0YNxM"
      },
      "source": [
        "Fijar semilla utilizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6d19Ve5hIlw",
        "outputId": "8b5edfec-0d63-4d35-a883-71b5ebd3bd2a"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMRcCYAcKPGp"
      },
      "source": [
        "# Dataset Boston house price\n",
        "Variables en orden:\n",
        "\n",
        "+ CRIM tasa de criminalidad per cápita por ciudad\n",
        "+ ZN proporción de terrenos residenciales zonificados para lotes de más de 25.000 pies cuadrados\n",
        "+ INDUS proporción de acres de negocios no minoristas por ciudad\n",
        "+ CHAS variable ficticia de Charles River (= 1 si el terreno limita con el río; 0 en caso contrario)\n",
        "+ NOX concentración de óxidos nítricos (partes por 10 millones)\n",
        "+ RM número promedio de habitaciones por vivienda\n",
        "+ AGE proporción de unidades ocupadas por sus propietarios construidas antes de 1940\n",
        "+ DIS distancias ponderadas a cinco centros de empleo de Boston\n",
        "+ RAD índice de accesibilidad a carreteras radiales\n",
        "+ TAX tasa de impuesto a la propiedad de valor total por cada $10.000\n",
        "+ PTRATIO relación alumno-maestro por ciudad\n",
        "+ B 1000(Bk - 0,63)^2 donde Bk es la proporción de poblacion afrodescendiente por ciudad\n",
        "+ LSTAT % de estatus inferior de la población\n",
        "+ MEDV Valor medio de las viviendas ocupadas por sus propietarios en miles de dólares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wDOxw4CkL-X2",
        "outputId": "c90887b8-b905-48c7-df1b-0a93af96aa2a"
      },
      "outputs": [],
      "source": [
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :3]])\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evio6dxYZnGE"
      },
      "source": [
        "Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1q7jL9xTdNE",
        "outputId": "0edb7c8c-74fe-4455-9eb0-3e578107c790"
      },
      "outputs": [],
      "source": [
        "data = df[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']].values\n",
        "target = df['MEDV'].values\n",
        "\n",
        "print(data.shape)\n",
        "print(target.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHcbfMW6ZqPv"
      },
      "source": [
        "## Exploración de Datos\n",
        "Realizar al menos:\n",
        "+ Displot - https://seaborn.pydata.org/generated/seaborn.displot.html\n",
        "+ Correlation Matrix - https://seaborn.pydata.org/generated/seaborn.heatmap.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M2sojTSdifu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwQ1vXt4eGEM"
      },
      "source": [
        "## Escalado de Datos\n",
        "\n",
        "Para evitar que una variable impacte más que otra, se debe escalar los datos de entrada, en este caso pueden emplear **MinMaxScaler**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-OHqXKSCUZc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhM140mJhEfe"
      },
      "source": [
        "## Carga de Dataset en Pytorch\n",
        "\n",
        "Para datos fuera de los ya incluidos en PyTorch, se debe crear el objeto Dataset acorde al entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqDD2u15fnR6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "class BostonDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X,dtype=torch.float32)\n",
        "        self.y = torch.tensor(y,dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "boston_dataset = BostonDataset(data, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxY_rp1MzkbG",
        "outputId": "e79c9b0f-1621-4082-a7e8-b47d058acd7f"
      },
      "outputs": [],
      "source": [
        "data, target = boston_dataset[0]\n",
        "print(data, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku7i6L1Y12sW"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int( * len(boston_dataset))\n",
        "test_size = len(boston_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(boston_dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwMM0kn3Q5uY"
      },
      "source": [
        "### Dataloaders\n",
        "\n",
        "A partir del dataset cargado generar un dataloader para entrenamiento y otro para validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hne9Lw_PQgw2"
      },
      "outputs": [],
      "source": [
        "batch_size =   # Elegir entre 64-128-256\n",
        "\n",
        "trainloader = \n",
        "valloader = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWGWzL-Dhexg"
      },
      "source": [
        "# Creación de Modelo\n",
        "Crear MLP con al menos 2 capas densas y 64 neuronas ocultas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-2F6_2aWobt"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      # Definir capas\n",
        "      self.linear1 = nn.Linear(13, 64)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = torch.relu(self.linear1(x))\n",
        "\n",
        "      return x\n",
        "\n",
        "model = MLP()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm_dNCUOfXz5"
      },
      "source": [
        "# Seleccion de Optimizador y Funcion de Costo\n",
        "Cosiderar que la tarea a realizar es Regresión.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WksHEjeSOTn"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion =  # Que funcion de perdida o criterio emplearias para este problema, revisar documentacion\n",
        "optimizer =  # Que optimizador o metodo emplearias, revisar documentacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGQYmHMIhHuP"
      },
      "source": [
        "# Entrenamiento\n",
        "Completar el código de entrenamiento tomando en consideración los siguientes pasos.\n",
        "\n",
        "+ Definir la cantidad de epocas a entrenar\n",
        "+ En un bucle se iteran los datos dentro del DataLoader de entrenamiento\n",
        "+ Se realiza el paso hacia adelante (o forward) obteniendo la prediccion para el batch\n",
        "+ Se computa el error obteniendo la funcion de perdida y se retropropaga el error en el paso hacia atras (o backward)\n",
        "+ Se actualizan los pesos mediante el optimizador en nuestro caso el gradiente descendente\n",
        "+ Se muestran, almacenan y/o calculan las metricas deseadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqq4d89hoOS_",
        "outputId": "96a14105-4c81-479a-ca53-e340f7fc0e8c"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 300\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    for inputs, labels in trainloader:\n",
        "        # setea los gradientes en 0\n",
        "\n",
        "        # forward\n",
        "\n",
        "        # backward\n",
        "\n",
        "\n",
        "        # optimizacion\n",
        "\n",
        "\n",
        "        # print statistics\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    average_train_loss = train_loss / len(trainloader)\n",
        "    train_losses.append(average_train_loss)\n",
        "\n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    average_validation_loss = val_loss / len(valloader)\n",
        "    val_losses.append(average_validation_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {average_train_loss:.4f}, Validation Loss: {average_validation_loss:.4f}\")\n",
        "\n",
        "print('Entrenamiento finalizado')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJgdtotm0dHp"
      },
      "source": [
        "Grafique ambas funciones de perdida utilizando matplotlib y comente sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "sldGUtIB0ohJ",
        "outputId": "54f0a2af-2055-4d25-ce40-ccfddf30bfe1"
      },
      "outputs": [],
      "source": [
        "plt.plot(, label='Train Loss')\n",
        "plt.plot(, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcO8c8pN1n-x"
      },
      "source": [
        "Guardado de modelo:\n",
        "\n",
        "Los pesos de los modelos entrenados se pueden almacenar mediante la funcion torch.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgHW3ylu1mWy"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './mlp_boston.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEkhTubl2Fay"
      },
      "source": [
        "Carga de modelo:\n",
        "\n",
        "Los pesos almacenados pueden ser cargados junto a la definicion del modelo(clase realizada previamente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lygUYx0_1uGy",
        "outputId": "93995fbe-0d25-4433-e774-46d5ca8e9d74"
      },
      "outputs": [],
      "source": [
        "cnn_loaded = MLP()\n",
        "cnn_loaded.load_state_dict(torch.load('./mlp_boston.pth', weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u53aCIT83frX"
      },
      "source": [
        "# Evaluación de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8NXCZ5k1TNG"
      },
      "outputs": [],
      "source": [
        "prediction = []\n",
        "labels = []\n",
        "cnn_loaded.eval()\n",
        "with torch.no_grad():\n",
        "    for input, label in valloader:\n",
        "        outputs = cnn_loaded(input)\n",
        "        prediction.append(outputs.numpy())\n",
        "        labels.append(label.numpy())\n",
        "\n",
        "prediction = np.concatenate(prediction)\n",
        "prediction = prediction.flatten()\n",
        "labels = np.concatenate(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxWaEU084D9V",
        "outputId": "324e9299-9a32-47c7-cf29-4e31d8a7d91a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, PredictionErrorDisplay\n",
        "\n",
        "mse = mean_squared_error(labels, prediction)\n",
        "mae = mean_absolute_error(labels, prediction)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f},MSE: {mse:.4f}, MAE: {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "oEFxnIq4bY41",
        "outputId": "3792df63-43eb-447f-adba-845c3b2c3913"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    labels,\n",
        "    y_pred=prediction,\n",
        "    kind=\"actual_vs_predicted\",\n",
        "    subsample=100,\n",
        "    ax=axs[0],\n",
        "    random_state=0,\n",
        ")\n",
        "axs[0].set_title(\"Valores reales vs. Valores predichos\")\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    labels,\n",
        "    y_pred=prediction,\n",
        "    kind=\"residual_vs_predicted\",\n",
        "    subsample=100,\n",
        "    ax=axs[1],\n",
        "    random_state=0,\n",
        ")\n",
        "axs[1].set_title(\"Residuos vs. Valores Predichos\")\n",
        "fig.suptitle(\"Gráficos de evaluación de predicciones\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuC-HeBdZA7J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
