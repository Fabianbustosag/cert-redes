{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Bp0tdq2Sb7"
      },
      "source": [
        "La libreria empleada para construir redes neuronales que emplearemos sera PyTorch.\n",
        "+ https://pytorch.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ywMrF4oKDzj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMRcCYAcKPGp"
      },
      "source": [
        "## Datasets\n",
        "El dataset empleado en este laboratorio es el CIFAR-10, el cual contiene 60000 imagenes a color de 32x32 pixeles ordenadas en 10 classes, con 6000 imagenes por clase.\n",
        "\n",
        "Pytorch ya incorpora este dataset. Todos los datasets incluidos en la libreria se pueden ver en el siguiente enlace:\n",
        "+ https://pytorch.org/vision/stable/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wDOxw4CkL-X2"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XcfdsM8KNlx",
        "outputId": "30f0e9cd-4136-46cb-e6b4-9c5c3dc61aa7"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6QybgU_NedX"
      },
      "source": [
        "Explora el dataset cargado:\n",
        "+ ¿Que tipo de dato es?\n",
        "+ ¿Cuales son sus atributos?\n",
        "+ ¿Que contiene el primer elemento?\n",
        "+ Muestra el primer elemento como imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Gegi57IsNlLZ",
        "outputId": "3008c33a-2620-4352-e2f0-bdc52f5d51e6"
      },
      "outputs": [],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuzEhsrVQXWU",
        "outputId": "bebd40d1-bd4b-4f09-95cd-9805555db0b5"
      },
      "outputs": [],
      "source": [
        " # llamar a la variable que almacena el conjuntos de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lZ4X35SOQOd",
        "outputId": "fcfba888-3c1b-4622-df14-b378997249ea"
      },
      "outputs": [],
      "source": [
        "dataset[][0].shape # con el metodo .shape revisa las dimensiones de las imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "9Sv9VJOnNdK1",
        "outputId": "7bcc547a-c5b8-4b39-efdd-5a746cbca98f"
      },
      "outputs": [],
      "source": [
        "img = dataset[][0].numpy() / 2 + 0.5 # quita la normalizacion de la imagen deseada para mostrar por pantalla\n",
        "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGHqKLmkw0Sl"
      },
      "source": [
        "### Reducir cantidad de datos\n",
        "En la demostracion en clases por motivos de tiempo reduciremos la cantidad de datos por categoria. En caso de querer reproducir con el dataset completo no correr estas celdas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TBrqvTqMxNCw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "targets = np.array(dataset.targets)\n",
        "num_classes = 10 # Número de clases en CIFAR-10\n",
        "\n",
        "# Número de ejemplos que se quiere por clase (puedes ajustarlo)\n",
        "samples_per_class = 100\n",
        "\n",
        "# Proporción del conjunto de validación (por ejemplo, 20% de los datos)\n",
        "validation_split = 0.2\n",
        "\n",
        "# Crear listas para los índices de entrenamiento y validación\n",
        "train_indices = []\n",
        "val_indices = []\n",
        "\n",
        "# Iterar sobre cada clase y dividir los índices en entrenamiento y validación\n",
        "for class_idx in range(num_classes):\n",
        "    # Obtener los índices de todos los ejemplos de la clase actual\n",
        "    class_indices = np.where(targets == class_idx)[0]\n",
        "\n",
        "    # Dividir los índices de la clase en entrenamiento y validación\n",
        "    train_idx, val_idx = train_test_split(class_indices, test_size=validation_split, random_state=42)\n",
        "\n",
        "    # Añadir los índices a las respectivas listas\n",
        "    train_indices.extend(train_idx)\n",
        "    val_indices.extend(val_idx)\n",
        "\n",
        "# Crear los subconjuntos de entrenamiento y validación\n",
        "train_subset = Subset(dataset, train_indices)\n",
        "val_subset = Subset(dataset, val_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwMM0kn3Q5uY"
      },
      "source": [
        "### Dataloaders\n",
        "\n",
        "Los Dataloaders nos ayudan a particionar cada dataset en bloques mas pequeños los cuales seran pasados durante el entrenamiento, estos se denominan **batch o mini-batch**.\n",
        "\n",
        "Un argumento relevante ademas del tamaño de cada **batch**, es si rebarajar o reordenar (shuffle) los datos, esto puede ayudar a reducir el sobreajuste (u overfitting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hne9Lw_PQgw2"
      },
      "outputs": [],
      "source": [
        "batch_size =  # Elegir numero de muestras por batch\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN-txGcEWpAi"
      },
      "source": [
        "## Red neuronal Convolucional - CNN\n",
        "\n",
        "Las CNN incorporan al menos 3 tipos de capas nuevas que trabajan con las imagenes:\n",
        "+ Convolucionales: Realizan convoluciones a las imagenes empleando un kernel de tamaño configurable\n",
        "+ Pooling: Realizan reduccion de dimensionalidad, aplicando promedios (Average Pooling), seleccionando los valores maximos (Max Pooling), entre otros\n",
        "+ Flatten: Toma los tensores y los aplana para poder se procesados por capas densas o lineales tradicionales\n",
        "\n",
        "En el siguiente bloque podras ver el resultado de una operacion de convolucion y de pooling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "W1pDBVM8XIDw",
        "outputId": "15045b33-9286-4b5a-df7e-d29bc78d9e02"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "imagen_demo = train_subset[][0] # Seleccionar imagen\n",
        "conv_demo = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3)\n",
        "conv_image = conv_demo(imagen_demo)\n",
        "print(conv_image.shape)\n",
        "\n",
        "pool_demo = nn.MaxPool2d(2,2)\n",
        "pool_image = pool_demo(conv_image)\n",
        "print(pool_image.shape)\n",
        "\n",
        "img = imagen_demo.permute(1,2,0).detach().numpy() / 2 + 0.5\n",
        "conv_img = conv_image[0].detach().numpy()\n",
        "pool_img = pool_image[0].detach().numpy()\n",
        "\n",
        "fig, axs = plt.subplots(1,3)\n",
        "axs[0].imshow(img)\n",
        "axs[1].imshow(conv_img)\n",
        "axs[2].imshow(pool_img)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYz69zGJecsY"
      },
      "source": [
        "### Creacion de CNN\n",
        "Para hacer una red neuronal en Pytorch es necesario crear un modulo, para esto se define una clase la cual heredara de nn.Module.\n",
        "Ademas para aplicar funciones de activacion a cada capa es necesario emplear el objeto functional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "p-2F6_2aWobt"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module): # Para rellenar\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3) # seleccionar kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # (16 - tamaño_kernel)/stride + 1 -> 11px\n",
        "                                          # A realizar pooling se debe dividir el canal en 2 y truncar la parte entera, 11/2->5\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # n_canales * alto_imagen * ancho_imagen\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "cnn = CNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm_dNCUOfXz5"
      },
      "source": [
        "## Seleccion de Optimizador y Funcion de Costo\n",
        "Debido a que la tarea seleccionada es la de clasificar a partir de multiples categorias, la funcion de perdida a utilizar es la entropia cruzada (Cross Entropy). La Funcion de costo sera la de Gradiente descendente estocastico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0WksHEjeSOTn"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion =  # Que funcion de perdida o criterio emplearias para este problema, revisar documentacion\n",
        "optimizer =  # Que optimizador o metodo emplearias, revisar documentacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGQYmHMIhHuP"
      },
      "source": [
        "## Entrenamiento\n",
        "Utilizando la red creada, el optimizador y la funcion de costo, procederemos a entrenar nuestra red, este procedimiento es iterativo y estara limitado por la cantidad de epocas que seleccionemos.\n",
        "\n",
        "Los pasos seguidos de forma general seran:\n",
        "+ Definir la cantidad de epocas a entrenar\n",
        "+ En un bucle se iteran los datos dentro del DataLoader de entrenamiento\n",
        "+ Se realiza el paso hacia adelante (o forward) obteniendo la prediccion para el batch\n",
        "+ Se computa el error obteniendo la funcion de perdida y se retropropaga el error en el paso hacia atras (o backward)\n",
        "+ Se actualizan los pesos mediante el optimizador en nuestro caso el gradiente descendente\n",
        "+ Se muestran, almacenan y/o calculan las metricas deseadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox9SKd6FhAc1",
        "outputId": "a28b6d56-3f8b-4d1f-8ed7-6f96217770c3"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        outputs = cnn(inputs)\n",
        "        # backward\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        # optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    average_loss = epoch_loss / len(trainloader)  # Calculate average loss for the epoch\n",
        "    losses.append(average_loss)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {average_loss:.4f}\")\n",
        "\n",
        "print('Entrenamiento finalizado')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "M2X-py9Rnjsl",
        "outputId": "b3e55d3d-a761-46b3-c90f-aeb90feb21f0"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7wcFVHunraJ"
      },
      "source": [
        "El codigo puede ser mejorado obteniendo metricas con un conjunto de validacion, esto con el fin de analizar el proceso de aprendizaje, generalizacion, underfitting y/o overfitting.\n",
        "\n",
        "Para realizar calculos con el modelo, por defecto se emplea el modo train(), para evitar modificar el modelo emplearemos el modo eval(), ademas para evitar el calculo de gradientes se desactiva el modulo autograd() el cual cumple esta funcion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqq4d89hoOS_",
        "outputId": "5d5e6c3e-e44d-4deb-bca4-6d0a8b5ff1c3"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = 0.0\n",
        "    cnn.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # setea los gradientes en 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        outputs = cnn(inputs)\n",
        "        # backward\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        # optimizacion\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    average_train_loss = train_loss / len(trainloader)\n",
        "    train_losses.append(average_train_loss)\n",
        "\n",
        "    val_loss = 0.0\n",
        "    cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            outputs = cnn(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    average_validation_loss = val_loss / len(testloader)\n",
        "    val_losses.append(average_validation_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {average_train_loss:.4f}, Validation Loss: {average_validation_loss:.4f}\")\n",
        "\n",
        "print('Entrenamiento finalizado')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJgdtotm0dHp"
      },
      "source": [
        "Grafique ambas funciones de perdida utilizando matplotlib y comente sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sldGUtIB0ohJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcO8c8pN1n-x"
      },
      "source": [
        "Guardado de modelo:\n",
        "\n",
        "Los pesos de los modelos entrenados se pueden almacenar mediante la funcion torch.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zgHW3ylu1mWy"
      },
      "outputs": [],
      "source": [
        "torch.save(cnn.state_dict(), './cnn_cifar10.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEkhTubl2Fay"
      },
      "source": [
        "Carga de modelo:\n",
        "\n",
        "Los pesos almacenados pueden ser cargados junto a la definicion del modelo(clase realizada previamente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lygUYx0_1uGy",
        "outputId": "0e9facaf-e8fd-483f-94cc-551a374272d5"
      },
      "outputs": [],
      "source": [
        "cnn_loaded = CNN()\n",
        "cnn_loaded.load_state_dict(torch.load('./cnn_cifar10.pth', weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATvU5yj12kx5"
      },
      "source": [
        "Prueba de modelo:\n",
        "\n",
        "Con el modelo cargado puedes seleccionar un dato del conjunto de validacion y realizar una prediccion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "yXtL7ZjS2XTx",
        "outputId": "87efb5f4-2043-4dbe-a374-f7c7c164b7cd"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imgs = torchvision.utils.make_grid(images)\n",
        "img = imgs / 2 + 0.5\n",
        "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "plt.show()\n",
        "\n",
        "outputs = cnn_loaded(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicho: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))\n",
        "print('Verdadero: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "j8NXCZ5k1TNG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
